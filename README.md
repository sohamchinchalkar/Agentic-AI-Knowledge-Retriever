# Agentic-AI-Knowledge-Retriever
Agentic AI system for domain-aware semantic retrieval and LLM-based synthesis from multi-source text data (URLs, CSV). Orchestrates embedding, clustering, vector search, and answer generation to deliver precise, contextual responses.

# ðŸ§  Domain-Oriented Agentic Retrieval & Synthesis System

An **agentic AI system** that autonomously retrieves, clusters, indexes, and synthesizes text-based answers from structured (CSV) and unstructured (URL) data sources. Designed to mimic a research assistant, the system uses semantic embeddings, domain-aware vector search, and LLM synthesis to deliver precise, context-rich responses via an interactive Colab UI.

---

## ðŸš€ Key Features

- **Agentic Orchestration**: A meta-agent coordinates chunking, embedding, clustering, retrieval, and synthesis steps based on query intent.
- **Domain-Aware Indexing**: Uses KMeans clustering to group semantic chunks by topic, then builds separate FAISS indices per domain for precise retrieval.
- **Semantic Chunking**: Processes and slices documents into overlapping text chunks to maintain context.
- **LLM-Based Synthesis**: Integrates Google's **Gemini** LLM to generate high-quality, natural-language answers from retrieved content.
- **Interactive Colab UI**: Provides an intuitive Python notebook interface for user queries and result display.

---

## ðŸ§± Tech Stack

| Component        | Tool/Library                |
|------------------|-----------------------------|
| Embedding        | `sentence-transformers` (MiniLM) |
| Clustering       | `scikit-learn` (KMeans)     |
| Vector Search    | `FAISS`                     |
| Synthesis        | `Gemini` (Google LLM)       |
| Data Sources     | `BeautifulSoup`, `pandas`   |
| Interface        | `Google Colab`, `Streamlit` (optional) |

---

## ðŸ“ˆ Performance Highlights

- âš¡ **5x faster retrieval** via domain-specific FAISS vs flat corpus search  
- ðŸ“š Supports **50K+ text chunks** across multiple domains with real-time response  
- ðŸŽ¯ Achieves **~90% relevance** (based on cosine similarity and qualitative feedback)



## ðŸ”§ How It Works

1. **Input**: Provide URLs or CSV files.
2. **Extraction**: Raw text is extracted and cleaned.
3. **Chunking**: Text is broken into overlapping chunks (to preserve context).
4. **Embedding**: Each chunk is encoded using SentenceTransformer (MiniLM).
5. **Clustering**: KMeans groups embeddings into semantic domains.
6. **Indexing**: FAISS index is built per domain.
7. **Retrieval**: Meta-agent selects relevant domain(s) based on query.
8. **Synthesis**: Retrieved chunks are passed to Gemini LLM for final answer.
9. **Output**: Synthesized answer is displayed in Colab.

---

## ðŸ“Œ Use Cases

- Research assistants for large document sets  
- Enterprise Q&A systems over internal data  
- Semantic search and summarization  
- Academic or market research bots
