{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "11465f1d68a44a4ba557ec4e955cabd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_860cd0894256442ab5892454c8681776",
              "IPY_MODEL_efca9fb69e984d16b5073ce3a40e3104",
              "IPY_MODEL_137b1b93b8ea4af990a45ed1bb474440"
            ],
            "layout": "IPY_MODEL_37af0a53542d4f3d8aaa5a32625280c8"
          }
        },
        "860cd0894256442ab5892454c8681776": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c970e4b7714b475faf8aece76ff04fdc",
            "placeholder": "​",
            "style": "IPY_MODEL_c836a5df23c04d58a9bd606b1ff3ef61",
            "value": "Batches: 100%"
          }
        },
        "efca9fb69e984d16b5073ce3a40e3104": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a3370c06006429db14ddb05241e3561",
            "max": 774,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f30156effdd64efcbe728c12249d9333",
            "value": 774
          }
        },
        "137b1b93b8ea4af990a45ed1bb474440": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c34f6d2293844de2a7796eccd0721b2a",
            "placeholder": "​",
            "style": "IPY_MODEL_e4ba01d7d27542c4b1825e2599c56375",
            "value": " 774/774 [00:36&lt;00:00, 127.54it/s]"
          }
        },
        "37af0a53542d4f3d8aaa5a32625280c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c970e4b7714b475faf8aece76ff04fdc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c836a5df23c04d58a9bd606b1ff3ef61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3a3370c06006429db14ddb05241e3561": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f30156effdd64efcbe728c12249d9333": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c34f6d2293844de2a7796eccd0721b2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4ba01d7d27542c4b1825e2599c56375": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# === STEP 0: Install dependencies ===\n",
        "!pip install -q sentence-transformers faiss-cpu scikit-learn langchain google-generativeai requests beautifulsoup4\n",
        "\n",
        "# === STEP 1: Imports ===\n",
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "import re\n",
        "from collections import Counter\n",
        "from sklearn.cluster import KMeans\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.parse import urljoin, urlparse\n",
        "import google.generativeai as genai\n",
        "import faiss\n",
        "\n",
        "\n",
        "# === STEP 2: Mount Drive for agent caching ===\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "CACHE_DIR = \"/content/drive/MyDrive/agents_cache\"\n",
        "os.makedirs(CACHE_DIR, exist_ok=True)\n",
        "\n",
        "# === STEP 3: Initialize models ===\n",
        "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "genai.configure(api_key=\"AIzaSyAtYlN4MV__hc3_pLrDhjH45_aaUEgkdpc\")  # Replace with your API key\n",
        "model = genai.GenerativeModel(\"models/gemini-2.5-flash\")\n",
        "\n",
        "# === STEP 4: Utility functions ===\n",
        "\n",
        "def clean_text(text):\n",
        "    return re.findall(r'\\b\\w+\\b', text.lower())\n",
        "\n",
        "def get_top_keywords(texts, top_n=3):\n",
        "    words = []\n",
        "    for t in texts:\n",
        "        words.extend(clean_text(t))\n",
        "    common = Counter(words).most_common(top_n)\n",
        "    return \", \".join([w for w, _ in common])\n",
        "\n",
        "def extract_text_from_url(url):\n",
        "    try:\n",
        "        res = requests.get(url, timeout=10)\n",
        "        soup = BeautifulSoup(res.text, 'html.parser')\n",
        "        for tag in soup([\"script\", \"style\", \"noscript\"]):\n",
        "            tag.decompose()\n",
        "        text = soup.get_text(separator=' ')\n",
        "        return ' '.join(text.split()), soup\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to fetch {url}: {e}\")\n",
        "        return \"\", None\n",
        "\n",
        "def cot_scrape(start_url, max_pages=10):\n",
        "    to_visit = [start_url]\n",
        "    visited = set()\n",
        "    all_texts = []\n",
        "    domain = urlparse(start_url).netloc\n",
        "    while to_visit and len(visited) < max_pages:\n",
        "        url = to_visit.pop(0)\n",
        "        if url in visited:\n",
        "            continue\n",
        "        print(f\"Scraping: {url}\")\n",
        "        text, soup = extract_text_from_url(url)\n",
        "        if text:\n",
        "            all_texts.append(text)\n",
        "        visited.add(url)\n",
        "        if soup:\n",
        "            for link in soup.find_all('a', href=True):\n",
        "                href = link['href']\n",
        "                full_url = urljoin(url, href)\n",
        "                parsed_url = urlparse(full_url)\n",
        "                if parsed_url.netloc == domain and full_url not in visited and full_url not in to_visit:\n",
        "                    to_visit.append(full_url)\n",
        "    return all_texts\n",
        "\n",
        "def create_faiss_index(texts):\n",
        "    docs = [Document(page_content=t) for t in texts]\n",
        "    embeddings = embedder.encode(texts, show_progress_bar=True)\n",
        "    dim = embeddings[0].shape[0]\n",
        "    index = faiss.IndexFlatL2(dim)\n",
        "    index.add(np.array(embeddings).astype('float32'))\n",
        "    return index, docs\n",
        "\n",
        "def save_agent(domain, index, docs):\n",
        "    safe_domain = domain.replace(\" \", \"_\")\n",
        "    path = os.path.join(CACHE_DIR, f\"{safe_domain}_agent.pkl\")\n",
        "    with open(path, \"wb\") as f:\n",
        "        pickle.dump({\"index\": index, \"docs\": docs}, f)\n",
        "    print(f\"Agent saved: {domain} → {path}\")\n",
        "\n",
        "def load_all_agents(agent_dir):\n",
        "    index_map, docs_map = {}, {}\n",
        "    for filename in os.listdir(agent_dir):\n",
        "        if filename.endswith(\"_agent.pkl\"):\n",
        "            domain = filename.replace(\"_agent.pkl\", \"\").replace(\"_\", \" \")\n",
        "            with open(os.path.join(agent_dir, filename), \"rb\") as f:\n",
        "                data = pickle.load(f)\n",
        "            index_map[domain] = data[\"index\"]\n",
        "            docs_map[domain] = data[\"docs\"]\n",
        "    return index_map, docs_map\n",
        "\n",
        "def select_relevant_agents(user_question, domains, threshold=0.75):\n",
        "    q_vec = embedder.encode([user_question])[0]\n",
        "    domain_vecs = embedder.encode(domains)\n",
        "    sims = [np.dot(q_vec, dv) / (np.linalg.norm(q_vec) * np.linalg.norm(dv) + 1e-10) for dv in domain_vecs]\n",
        "    ranked = sorted(zip(domains, sims), key=lambda x: x[1], reverse=True)\n",
        "    selected = [d for d, s in ranked if s >= threshold]\n",
        "    if not selected:\n",
        "        selected = [d for d, _ in ranked[:2]]\n",
        "    return selected\n",
        "\n",
        "def search_documents(index, docs, query, top_k=3, alpha=0.7):\n",
        "    q_vec = embedder.encode([query])[0].astype(\"float32\")\n",
        "    D, I = index.search(q_vec.reshape(1, -1), top_k * 3)\n",
        "    results = []\n",
        "    query_keywords = set(clean_text(query))\n",
        "    for idx in I[0]:\n",
        "        if 0 <= idx < len(docs):\n",
        "            doc = docs[idx]\n",
        "            doc_keywords = set(clean_text(doc.page_content))\n",
        "            keyword_score = len(query_keywords & doc_keywords) / (len(query_keywords) + 1e-5)\n",
        "            semantic_score = 1.0 / (D[0][list(I[0]).index(idx)] + 1e-5)\n",
        "            hybrid_score = alpha * semantic_score + (1 - alpha) * keyword_score\n",
        "            results.append((hybrid_score, doc))\n",
        "    results = sorted(results, key=lambda x: x[0], reverse=True)\n",
        "    return [doc for _, doc in results[:top_k]]\n",
        "\n",
        "def generate_answer(domain, context, query):\n",
        "    prompt = f\"\"\"You are a helpful assistant specialized in the {domain} domain.\n",
        "Use only the context below to answer the question.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question:\n",
        "{query}\n",
        "\n",
        "Answer:\"\"\"\n",
        "    response = model.generate_content(prompt)\n",
        "    return response.text.strip()\n",
        "\n",
        "def synthesize_combined_answer(agent_answers, user_question):\n",
        "    combined_text = \"\\n\\n\".join([\n",
        "        f\"[{domain} Agent]: {ans}\\nConfidence: {confidence:.2f}\"\n",
        "        for domain, ans, confidence in agent_answers\n",
        "    ])\n",
        "    prompt = f\"\"\"\n",
        "You are an expert assistant that received the following answers from multiple specialized agents for the user's question.\n",
        "\n",
        "User question: {user_question}\n",
        "\n",
        "Agent answers: {combined_text}\n",
        "\n",
        "Compare the answers step by step. Rank them based on relevance and correctness. Then synthesize a final answer by selecting the best one or merging them into a superior response.\n",
        "\n",
        "Return your reasoning, ranked list, and final answer.\n",
        "\"\"\"\n",
        "    response = model.generate_content(prompt)\n",
        "    return response.text.strip()\n",
        "\n",
        "# === STEP 5: Main interactive logic ===\n",
        "\n",
        "def create_agents_from_csv(filename):\n",
        "    with open(filename, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "        lines = f.read().splitlines()\n",
        "    block_size = 5\n",
        "    all_texts = [\n",
        "        \" \".join(lines[i:i + block_size]).strip()\n",
        "        for i in range(0, len(lines), block_size)\n",
        "        if \" \".join(lines[i:i + block_size]).strip()\n",
        "    ]\n",
        "    print(f\"Parsed {len(all_texts)} blocks from CSV.\")\n",
        "    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
        "    docs = splitter.create_documents(all_texts)\n",
        "    print(f\"Created {len(docs)} documents.\")\n",
        "    doc_texts = [doc.page_content for doc in docs]\n",
        "    embeddings = embedder.encode(doc_texts, show_progress_bar=True)\n",
        "    num_clusters = min(5, len(docs))\n",
        "    kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
        "    labels = kmeans.fit_predict(embeddings)\n",
        "    domain_names = []\n",
        "    for cluster_id in range(num_clusters):\n",
        "        cluster_indices = [i for i, label in enumerate(labels) if label == cluster_id]\n",
        "        cluster_texts = [doc_texts[i] for i in cluster_indices]\n",
        "        cluster_docs = [docs[i] for i in cluster_indices]\n",
        "        domain_name = get_top_keywords(cluster_texts) or f\"Domain_{cluster_id}\"\n",
        "        domain_names.append(domain_name)\n",
        "        cluster_embeddings = [embeddings[i] for i in cluster_indices]\n",
        "        dim = cluster_embeddings[0].shape[0]\n",
        "        index = faiss.IndexFlatL2(dim)\n",
        "        index.add(np.array(cluster_embeddings).astype(\"float32\"))\n",
        "        save_agent(domain_name, index, cluster_docs)\n",
        "    print(f\"Created agents for domains: {domain_names}\")\n",
        "\n",
        "def create_agents_from_url(url):\n",
        "    all_texts = cot_scrape(url)\n",
        "    if not all_texts:\n",
        "        print(\"No content scraped from URL.\")\n",
        "        return\n",
        "    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
        "    docs = splitter.create_documents(all_texts)\n",
        "    print(f\"Created {len(docs)} documents from URL scraping.\")\n",
        "    doc_texts = [doc.page_content for doc in docs]\n",
        "    embeddings = embedder.encode(doc_texts, show_progress_bar=True)\n",
        "    num_clusters = min(5, len(docs))\n",
        "    kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
        "    labels = kmeans.fit_predict(embeddings)\n",
        "    domain_names = []\n",
        "    for cluster_id in range(num_clusters):\n",
        "        cluster_indices = [i for i, label in enumerate(labels) if label == cluster_id]\n",
        "        cluster_texts = [doc_texts[i] for i in cluster_indices]\n",
        "        cluster_docs = [docs[i] for i in cluster_indices]\n",
        "        domain_name = get_top_keywords(cluster_texts) or f\"Domain_{cluster_id}\"\n",
        "        domain_names.append(domain_name)\n",
        "        cluster_embeddings = [embeddings[i] for i in cluster_indices]\n",
        "        dim = cluster_embeddings[0].shape[0]\n",
        "        index = faiss.IndexFlatL2(dim)\n",
        "        index.add(np.array(cluster_embeddings).astype(\"float32\"))\n",
        "        save_agent(domain_name, index, cluster_docs)\n",
        "    print(f\"Created agents for domains: {domain_names}\")\n",
        "\n",
        "def interactive_qa():\n",
        "    index_map, docs_map = load_all_agents(CACHE_DIR)\n",
        "    if not index_map:\n",
        "        print(\"No agents found in cache. Please create agents first from CSV or URL.\")\n",
        "        return\n",
        "    chat_history = []\n",
        "    while True:\n",
        "        question = input(\"\\nAsk your question (or 'exit' to quit): \").strip()\n",
        "        if question.lower() == \"exit\":\n",
        "            print(\"Goodbye!\")\n",
        "            break\n",
        "        selected_domains = select_relevant_agents(question, list(index_map.keys()))\n",
        "        agent_answers = []\n",
        "        for domain in selected_domains:\n",
        "            index = index_map[domain]\n",
        "            docs = docs_map[domain]\n",
        "            top_docs = search_documents(index, docs, question)\n",
        "            context = \"\\n\\n\".join(doc.page_content for doc in top_docs)\n",
        "            answer = generate_answer(domain, context, question)\n",
        "            agent_answers.append((domain, answer, 0.9))  # skipping confidence scoring for now\n",
        "        final_answer = synthesize_combined_answer(agent_answers, question)\n",
        "        chat_history.append((\"You\", question))\n",
        "        chat_history.append((\"Combined Insight\", final_answer))\n",
        "        print(\"\\n🤖 Combined Insight:\\n\", final_answer)\n",
        "\n",
        "# === USAGE ===\n",
        "print(\"Welcome! To create agents from CSV, call: create_agents_from_csv('yourfile.csv')\")\n",
        "print(\"To create agents from URL, call: create_agents_from_url('https://example.com')\")\n",
        "print(\"After agents are created, call interactive_qa() to chat with your multi-agent system.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dswKCQcuuBY8",
        "outputId": "2750d104-5bdd-431d-9368-69ee3cd22c37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Welcome! To create agents from CSV, call: create_agents_from_csv('yourfile.csv')\n",
            "To create agents from URL, call: create_agents_from_url('https://example.com')\n",
            "After agents are created, call interactive_qa() to chat with your multi-agent system.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "create_agents_from_csv('kizen_resources.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188,
          "referenced_widgets": [
            "11465f1d68a44a4ba557ec4e955cabd3",
            "860cd0894256442ab5892454c8681776",
            "efca9fb69e984d16b5073ce3a40e3104",
            "137b1b93b8ea4af990a45ed1bb474440",
            "37af0a53542d4f3d8aaa5a32625280c8",
            "c970e4b7714b475faf8aece76ff04fdc",
            "c836a5df23c04d58a9bd606b1ff3ef61",
            "3a3370c06006429db14ddb05241e3561",
            "f30156effdd64efcbe728c12249d9333",
            "c34f6d2293844de2a7796eccd0721b2a",
            "e4ba01d7d27542c4b1825e2599c56375"
          ]
        },
        "id": "POgOkdyPvX0A",
        "outputId": "7581f945-2507-4589-a292-611f53138af0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parsed 18262 blocks from CSV.\n",
            "Created 24753 documents.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/774 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "11465f1d68a44a4ba557ec4e955cabd3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Agent saved: and, to, the → /content/drive/MyDrive/agents_cache/and,_to,_the_agent.pkl\n",
            "Agent saved: and, ai, the → /content/drive/MyDrive/agents_cache/and,_ai,_the_agent.pkl\n",
            "Agent saved: kizen, com, https → /content/drive/MyDrive/agents_cache/kizen,_com,_https_agent.pkl\n",
            "Agent saved: kizen, com, 1 → /content/drive/MyDrive/agents_cache/kizen,_com,_1_agent.pkl\n",
            "Agent saved: 2023, 2022, kizen → /content/drive/MyDrive/agents_cache/2023,_2022,_kizen_agent.pkl\n",
            "Created agents for domains: ['and, to, the', 'and, ai, the', 'kizen, com, https', 'kizen, com, 1', '2023, 2022, kizen']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "interactive_qa()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jsDw6_ZyvkRO",
        "outputId": "69746a3b-079d-446f-8215-bf07d8178609"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Ask your question (or 'exit' to quit): Who is the ceo of Kizen?\n",
            "\n",
            "🤖 Combined Insight:\n",
            " **Reasoning:**\n",
            "\n",
            "The user is asking a specific factual question: \"Who is the CEO of Kizen?\".\n",
            "*   **Agent 1 ([and, kizen, to Agent]):** States that the information about the CEO is \"not available\" based on its provided context. It then provides tangential information about other individuals associated with Kizen as users. While this agent is honest about its limitations, it fails to answer the user's core question.\n",
            "*   **Agent 2 ([kizen, com, 1 Agent]):** Directly provides a specific name, \"John Winner,\" as the CEO of Kizen. This agent directly addresses the user's question with a definitive answer.\n",
            "\n",
            "Agent 2 is more relevant and useful as it provides a direct answer to the user's query, whereas Agent 1 indicates a lack of information within its specific dataset. Assuming the information provided by Agent 2 is accurate (which is implied by its direct statement), it is superior.\n",
            "\n",
            "**Ranked List:**\n",
            "\n",
            "1.  **[kizen, com, 1 Agent]:** Directly answers the user's question. (Relevance: High, Correctness: Assumed High)\n",
            "2.  **[and, kizen, to Agent]:** States that the information is not available within its context, failing to answer the user's question directly. (Relevance: Low, Correctness: True for its context but unhelpful for the query)\n",
            "\n",
            "**Final Answer:**\n",
            "\n",
            "John Winner is the CEO of Kizen.\n",
            "\n",
            "Ask your question (or 'exit' to quit): how is kizen working on marketing?\n",
            "\n",
            "🤖 Combined Insight:\n",
            " **Reasoning:**\n",
            "\n",
            "1.  **Agent 1 Evaluation:** This agent directly addresses the user's question by stating that Kizen works on marketing by \"offering a Marketing Platform designed to boost engagement and automate campaigns.\" The source `kizen, com` suggests this information likely comes directly from Kizen's official communication or website, which increases its credibility and relevance. This answer interprets \"how is Kizen working on marketing?\" as \"what does Kizen provide in the marketing space?\" which is a very common and reasonable interpretation.\n",
            "\n",
            "2.  **Agent 2 Evaluation:** This agent claims \"there is no information about how Kizen is working on marketing.\" This directly contradicts Agent 1's finding. While it lists other services Kizen provides (growing sales, automating tasks, tracking students), these are general business functions and don't specifically answer how Kizen is involved *in* marketing or what their marketing *offering* is, which Agent 1 successfully identifies. The assertion of \"no information\" makes it less helpful, especially when another agent provides relevant data.\n",
            "\n",
            "**Conclusion on Comparison:**\n",
            "Agent 1 provides a direct, relevant, and credible answer to the user's question. Agent 2 fails to provide relevant information and incorrectly states an absence of information.\n",
            "\n",
            "---\n",
            "\n",
            "**Ranked List:**\n",
            "\n",
            "1.  **Agent 1** (Relevance: High, Correctness: High) - Directly answers the question by explaining Kizen's marketing-related offerings.\n",
            "2.  **Agent 2** (Relevance: Low, Correctness: Low) - Incorrectly states a lack of information and provides general, non-specific details.\n",
            "\n",
            "---\n",
            "\n",
            "**Final Answer:**\n",
            "\n",
            "Kizen works on marketing by offering a **Marketing Platform** designed to **boost engagement and automate campaigns**.\n",
            "\n",
            "Ask your question (or 'exit' to quit): what is AI in business?\n",
            "\n",
            "🤖 Combined Insight:\n",
            " **Reasoning:**\n",
            "\n",
            "1.  **Agent 1 ([ai, and, to Agent]) Analysis:**\n",
            "    *   **Definition:** This agent defines \"AI in business\" as \"a network of specially-trained AI labor\" and \"Pre-Trained expert AI agents.\"\n",
            "    *   **Strengths:** It highlights a specific, albeit narrow, application of AI in business (AI as a workforce/agent).\n",
            "    *   **Weaknesses:** The definition is highly specific and does not encompass the broader meaning of AI in business. It treats AI as a type of digital employee rather than a set of technologies applied across various business functions. It lacks the general understanding of what AI *is* before applying it to business. Its focus is on a particular product or service model involving AI.\n",
            "    *   **Relevance & Correctness:** Partially relevant for a niche interpretation, but not broadly correct or comprehensive for \"what is AI in AI in business.\"\n",
            "\n",
            "2.  **Agent 2 ([and, ai, the Agent]) Analysis:**\n",
            "    *   **Definition:** This agent defines \"AI in business\" as \"the application of artificial intelligence technologies within a business context.\" This is a robust and accurate starting point.\n",
            "    *   **Strengths:** It provides a broad, accurate, and comprehensive understanding. It explains the *purpose* of AI in business (changing traditional methods, data-driven decisions, improving experiences, efficiency) and lists a wide range of practical applications and benefits (processing data, predictions, learning, understanding language, automation, etc.). This answer directly addresses the \"what\" and \"how\" of AI in business.\n",
            "    *   **Weaknesses:** None significant.\n",
            "    *   **Relevance & Correctness:** Highly relevant and correct, offering a complete picture.\n",
            "\n",
            "**Comparison and Ranking:**\n",
            "\n",
            "Agent 2 is vastly superior. It offers a general, accurate, and comprehensive definition of AI in business, focusing on the application of various AI technologies and their wide-ranging benefits. Agent 1, while touching upon a valid (but narrow) application, does not provide a general definition of \"AI in business\" but rather describes a specific type of AI solution (AI as labor/agents).\n",
            "\n",
            "**Ranked List:**\n",
            "\n",
            "1.  **[and, ai, the Agent]** (Score: 5/5 - Comprehensive, accurate, highly relevant)\n",
            "2.  **[ai, and, to Agent]** (Score: 2/5 - Too narrow, specific interpretation rather than a general definition)\n",
            "\n",
            "---\n",
            "\n",
            "**Final Answer:**\n",
            "\n",
            "AI in business refers to the application of artificial intelligence technologies within a business context. It is an integral part of modern business operations, fundamentally changing traditional methods by enabling organizations to make data-driven decisions, enhance customer experiences, develop innovative products and services, and significantly increase operational efficiency.\n",
            "\n",
            "AI helps businesses to:\n",
            "*   Process and analyze massive amounts of data\n",
            "*   Make accurate predictions and forecasts\n",
            "*   Learn from patterns and experiences to optimize performance\n",
            "*   Understand and interpret human language (e.g., customer queries, sentiment)\n",
            "*   Streamline and automate repetitive processes\n",
            "*   Support informed decision-making\n",
            "*   Provide personalized customer experiences and recommendations\n",
            "*   Solve complex problems across various domains\n",
            "\n",
            "Ask your question (or 'exit' to quit): okay thanks!\n",
            "\n",
            "🤖 Combined Insight:\n",
            " **Reasoning:**\n",
            "\n",
            "1.  **Understand User Input:** The user's input \"okay thanks!\" is a conversational closing, not a question requiring an informational answer.\n",
            "2.  **Evaluate Agent 1 ([kizen, com, 1 Agent]):** This agent correctly identifies its limitation (\"I can only answer questions based on the provided context\") and explains why it cannot respond to the specific phrase (\"The context does not contain information on how to respond to 'okay thanks!'\"). This is accurate and helpful in explaining its functionality.\n",
            "3.  **Evaluate Agent 2 ([kizen, com, https Agent]):** This agent also correctly identifies that no question was provided. It's concise and accurate, but less specific in its explanation compared to Agent 1.\n",
            "4.  **Comparison:** Both agents correctly understand that the user's input is not a query they are designed to handle. Agent 1 is slightly superior because it directly references the user's phrase (\"okay thanks!\") and provides a clearer reason for its inability to respond (lack of context for that specific conversational element), making its response a bit more informative for the user.\n",
            "\n",
            "**Ranked List:**\n",
            "\n",
            "1.  **[kizen, com, 1 Agent]:** \"I can only answer questions based on the provided context. The context does not contain information on how to respond to \"okay thanks!\". Confidence: 0.90\n",
            "2.  **[kizen, com, https Agent]:** \"There isn't a question provided for me to answer from the given context.\" Confidence: 0.90\n",
            "\n",
            "**Final Answer:**\n",
            "\n",
            "Your input \"okay thanks!\" is not a question that can be answered based on the provided context.\n",
            "\n",
            "Ask your question (or 'exit' to quit): exit\n",
            "Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M4-1-6WYwU9x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}